{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 04:27:18.521900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734668838.543012  215899 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734668838.549643  215899 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- for working with directory ----------------------------\n",
    "ROOT_DATA_PATH='/workspace/datasets'\n",
    "DATASET_PATH=f'{ROOT_DATA_PATH}/rsna-intracranial-hemorrhage-detection'\n",
    "\n",
    "TRAIN_DATA_PATH=f'{DATASET_PATH}/stage_2_train'\n",
    "TRAIN_SINOGRAM_DATA_PATH=f'{DATASET_PATH}/stage_2_train_sinogram'\n",
    "TRAIN_METADATA_PATH=f'{DATASET_PATH}/processed_metadata/train_metadata_df.pkl'\n",
    "\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (360, 362)\n",
    "IMG_SHAPE = (*IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sinogram(fpath):\n",
    "    im = None\n",
    "    try:\n",
    "        im = np.load(fpath).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print('\\nWarning:', e.__class__.__name__, f'for {fpath} Replacing with zeros sinogram values')\n",
    "        im = np.zeros(IMG_SHAPE, dtype=np.float32)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSinoDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, img_ids, labels, img_dir, img_shape, num_classes, batch_size, under_sampling=False, shuffle_on_epoch_end=True, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.img_ids = img_ids\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.under_sampling = under_sampling\n",
    "        self.shuffle_on_epoch_end = shuffle_on_epoch_end\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.img_ids) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low = index*self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.img_ids))\n",
    "        indices = self.indices[low:high]\n",
    "        X,y = self.__data_generation(indices)\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_ids))\n",
    "        \n",
    "        if self.under_sampling:\n",
    "            keep_prob = self.labels.iloc[:,0].map({0: 0.35, 1: 0.5})\n",
    "            keep = (keep_prob > np.random.rand(len(keep_prob)))\n",
    "            self.indices = self.indices[keep]\n",
    "            \n",
    "        if self.shuffle_on_epoch_end:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_shape))\n",
    "        y = np.empty((self.batch_size, self.num_classes), dtype=np.float32)\n",
    "        \n",
    "        for i, img_idx in enumerate(indices):\n",
    "            img_id = self.img_ids[img_idx]\n",
    "            img_path = f'{self.img_dir}/{img_id}.npy'\n",
    "            img = read_sinogram(img_path)\n",
    "            X[i,] = img\n",
    "            y[i,] = self.labels.iloc[img_idx].values\n",
    "            \n",
    "        return X,y\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_99196d0ab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_2b0190b58</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_056e14224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_525e72262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b00eddf10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_21e825c20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_85141c704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b4add57dd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_02f0d7dbb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_7d29263ce</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263606 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                                          \\\n",
       "Diagnosis      any epidural intraparenchymal intraventricular subarachnoid   \n",
       "Image                                                                        \n",
       "ID_99196d0ab     1        0                0                0            0   \n",
       "ID_2b0190b58     0        0                0                0            0   \n",
       "ID_056e14224     1        1                0                0            0   \n",
       "ID_525e72262     0        0                0                0            0   \n",
       "ID_b00eddf10     0        0                0                0            0   \n",
       "...            ...      ...              ...              ...          ...   \n",
       "ID_21e825c20     0        0                0                0            0   \n",
       "ID_85141c704     1        0                1                0            0   \n",
       "ID_b4add57dd     0        0                0                0            0   \n",
       "ID_02f0d7dbb     0        0                0                0            0   \n",
       "ID_7d29263ce     1        0                0                0            0   \n",
       "\n",
       "                       \n",
       "Diagnosis    subdural  \n",
       "Image                  \n",
       "ID_99196d0ab        1  \n",
       "ID_2b0190b58        0  \n",
       "ID_056e14224        0  \n",
       "ID_525e72262        0  \n",
       "ID_b00eddf10        0  \n",
       "...               ...  \n",
       "ID_21e825c20        0  \n",
       "ID_85141c704        1  \n",
       "ID_b4add57dd        0  \n",
       "ID_02f0d7dbb        0  \n",
       "ID_7d29263ce        1  \n",
       "\n",
       "[263606 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(TRAIN_METADATA_PATH)\n",
    "test_df_neg = df[df['Label']['any'] == 0].sample(n=200)\n",
    "test_df_pos = df[df['Label']['any'] == 1].sample(n=200)\n",
    "test_df = pd.concat([test_df_pos, test_df_neg]).sample(frac=1)\n",
    "df = df.drop(test_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "0    146510\n",
       "1    117096\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "1    200\n",
       "0    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinoDeepModel():\n",
    "    def __init__(self, base,input_shape, batch_size, num_epochs, num_classes, learning_rate, decay_rate, decay_steps, base_name='base_model', weights='imagenet', freeze_base=False, saving_path=None, verbose=1):\n",
    "        self.base = base\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.base_name = base_name\n",
    "        self.weights = weights\n",
    "        self.freeze_base = freeze_base\n",
    "        self.saving_path = saving_path\n",
    "        self.verbose = verbose\n",
    "        self._build()\n",
    "        self._create_saving_path_if_none()\n",
    "    \n",
    "    def _build(self):\n",
    "        K.clear_session()\n",
    "        base = self.base(include_top=False, weights=self.weights, pooling='avg', input_shape=self.input_shape)\n",
    "        base.trainable = not self.freeze_base\n",
    "            \n",
    "        x = base.output\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        out = layers.Dense(self.num_classes, activation='sigmoid', name='dense_output')(x)\n",
    "        \n",
    "        self.model = keras.models.Model(inputs=base.input, outputs=out)\n",
    "        \n",
    "        \n",
    "        self.model.compile(\n",
    "            loss=keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=keras.optimizers.AdamW(learning_rate=self.learning_rate),\n",
    "            metrics=[\n",
    "                keras.metrics.TruePositives(name='tp'),\n",
    "                keras.metrics.TrueNegatives(name='tn'),\n",
    "                keras.metrics.FalsePositives(name='fp'),\n",
    "                keras.metrics.FalseNegatives(name='fn'),\n",
    "                keras.metrics.BinaryAccuracy(name='binary_acc'), \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc_roc', curve='ROC', multi_label=True, num_labels=self.num_classes),\n",
    "                keras.metrics.AUC(name='auc_pr', curve='PR', multi_label=True, num_labels=self.num_classes),\n",
    "                keras.metrics.F1Score(name='f1_score', average='weighted'),                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def _create_saving_path_if_none(self):\n",
    "        if self.saving_path is None:\n",
    "            print('saving_path is None. Automatically create path for save training utilities')\n",
    "            saving_path = os.path.join('saved_model', self.base.__name__)\n",
    "            os.makedirs(saving_path, exist_ok=True)\n",
    "            self.saving_path = saving_path\n",
    "            print(self.saving_path, 'created for saving_path')\n",
    "        \n",
    "    def fit(self, train_df, valid_df):\n",
    "        train_data_gen = TrainSinoDataGenerator(\n",
    "            img_ids=train_df.index, \n",
    "            labels=train_df,\n",
    "            img_dir=TRAIN_SINOGRAM_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        valid_data_gen = TrainSinoDataGenerator(\n",
    "            img_ids=valid_df.index, \n",
    "            labels=valid_df,\n",
    "            img_dir=TRAIN_SINOGRAM_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        curr_time = int(time.time())\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(filepath='%s/{epoch:02d}-%s.weights.h5' % (self.saving_path, curr_time), monitor='val_loss', mode='min', verbose=self.verbose, save_weights_only=True, save_best_only=False),\n",
    "            keras.callbacks.LearningRateScheduler(lambda epoch: self.learning_rate * pow(self.decay_rate, math.floor(epoch / self.decay_steps)), verbose=1),\n",
    "            keras.callbacks.EarlyStopping(verbose=1, restore_best_weights=True, monitor='val_loss', patience=4, mode='min'),\n",
    "            keras.callbacks.CSVLogger(filename='%s/%s.csv'%(self.saving_path, f'{curr_time}-train_log'))\n",
    "        ]\n",
    "        return self.model.fit(\n",
    "            x=train_data_gen,\n",
    "            validation_data=valid_data_gen,\n",
    "            callbacks=callbacks,\n",
    "            epochs=self.num_epochs,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "    \n",
    "    def save(self, filename, overwrite=True):\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        if ext != '.keras':\n",
    "          filename = f'{filename}.keras'\n",
    "          \n",
    "        p = os.path.join(self.saving_path, filename)\n",
    "        self.model.save(p, overwrite=overwrite)\n",
    "        print('model saved to:', p)\n",
    "        \n",
    "    def load_weights(self, path, *args, **kwargs):\n",
    "        self.model.load_weights(path, *args, **kwargs)\n",
    "        \n",
    "    def load(self, path, *args, **kwargs):\n",
    "        self.model = keras.models.load_model(path, *args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 15\n",
    "INPUT_SHAPE = IMG_SHAPE\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 6\n",
    "INITIAL_LEARNING_RATE = 0.000125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "msss = MultilabelStratifiedShuffleSplit(n_splits=EPOCH, test_size=0.15, random_state=SEED)\n",
    "X = df.index\n",
    "Y = df['Label'].values\n",
    "\n",
    "msss_splits = next(msss.split(X, Y))\n",
    "train_idx = msss_splits[0]\n",
    "valid_idx = msss_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734669215.392711  215899 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8225 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.10gb, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "saving_path = 'saved_model/02_EfficientNetB4_V2_sinogram_input'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "model = SinoDeepModel(\n",
    "    base=keras.applications.EfficientNetB4,\n",
    "    weights='imagenet',\n",
    "    freeze_base=False,\n",
    "    input_shape=INPUT_SHAPE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_epochs=EPOCH,\n",
    "    num_classes=N_CLASSES,\n",
    "    learning_rate=INITIAL_LEARNING_RATE, \n",
    "    decay_rate=0.75, \n",
    "    decay_steps=1,\n",
    "    base_name='efficientnetb4',\n",
    "    saving_path=saving_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.000125.\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734669973.162622  216448 service.cc:148] XLA service 0x7fe73c003d50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734669973.162662  216448 service.cc:156]   StreamExecutor device (0): NVIDIA A100-SXM4-40GB MIG 1g.10gb, Compute Capability 8.0\n",
      "I0000 00:00:1734669983.116799  216448 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "E0000 00:00:1734669995.914235  216448 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1734669996.101655  216448 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "I0000 00:00:1734670059.003130  216448 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step - auc_pr: 0.5782 - auc_roc: 0.8643 - binary_acc: 0.8833 - f1_score: 0.2777 - fn: 54437.2891 - fp: 19156.0078 - loss: 0.2811 - precision: 0.7516 - recall: 0.5125 - tn: 533661.2500 - tp: 65129.4844\n",
      "Epoch 1: val_loss improved from inf to 1.16363, saving model to saved_model/02_EfficientNetB4_V2_sinogram_input/01-1734669867.weights.h5\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6659s\u001b[0m 924ms/step - auc_pr: 0.5782 - auc_roc: 0.8643 - binary_acc: 0.8833 - f1_score: 0.2777 - fn: 54443.7812 - fp: 19158.5820 - loss: 0.2810 - precision: 0.7516 - recall: 0.5125 - tn: 533737.6250 - tp: 65140.0117 - val_auc_pr: 0.1785 - val_auc_roc: 0.5024 - val_binary_acc: 0.8222 - val_f1_score: 0.0341 - val_fn: 42194.0000 - val_fp: 0.0000e+00 - val_loss: 1.1636 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 195118.0000 - val_tp: 0.0000e+00 - learning_rate: 1.2500e-04\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 9.375e-05.\n",
      "Epoch 2/15\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807ms/step - auc_pr: 0.8245 - auc_roc: 0.9465 - binary_acc: 0.9242 - f1_score: 0.3309 - fn: 34596.9961 - fp: 15823.2539 - loss: 0.1861 - precision: 0.8412 - recall: 0.7055 - tn: 537223.8125 - tp: 84739.9609\n",
      "Epoch 2: val_loss improved from 1.16363 to 0.37076, saving model to saved_model/02_EfficientNetB4_V2_sinogram_input/02-1734669867.weights.h5\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6495s\u001b[0m 925ms/step - auc_pr: 0.8245 - auc_roc: 0.9465 - binary_acc: 0.9242 - f1_score: 0.3309 - fn: 34601.7031 - fp: 15825.4609 - loss: 0.1861 - precision: 0.8412 - recall: 0.7055 - tn: 537300.5000 - tp: 84752.3047 - val_auc_pr: 0.5804 - val_auc_roc: 0.8386 - val_binary_acc: 0.8642 - val_f1_score: 0.3045 - val_fn: 31065.0000 - val_fp: 1172.0000 - val_loss: 0.3708 - val_precision: 0.9048 - val_recall: 0.2638 - val_tn: 193942.0000 - val_tp: 11133.0000 - learning_rate: 9.3750e-05\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 7.031250000000001e-05.\n",
      "Epoch 3/15\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800ms/step - auc_pr: 0.8964 - auc_roc: 0.9696 - binary_acc: 0.9436 - f1_score: 0.3642 - fn: 24742.1035 - fp: 13021.2295 - loss: 0.1404 - precision: 0.8792 - recall: 0.7916 - tn: 539819.4375 - tp: 94801.2578\n",
      "Epoch 3: val_loss improved from 0.37076 to 0.28995, saving model to saved_model/02_EfficientNetB4_V2_sinogram_input/03-1734669867.weights.h5\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6433s\u001b[0m 915ms/step - auc_pr: 0.8964 - auc_roc: 0.9696 - binary_acc: 0.9436 - f1_score: 0.3642 - fn: 24745.5605 - fp: 13023.0703 - loss: 0.1404 - precision: 0.8792 - recall: 0.7916 - tn: 539896.5000 - tp: 94814.8203 - val_auc_pr: 0.7001 - val_auc_roc: 0.8957 - val_binary_acc: 0.8878 - val_f1_score: 0.3360 - val_fn: 15618.0000 - val_fp: 11007.0000 - val_loss: 0.2900 - val_precision: 0.7071 - val_recall: 0.6299 - val_tn: 184110.0000 - val_tp: 26577.0000 - learning_rate: 7.0312e-05\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 5.2734375e-05.\n",
      "Epoch 4/15\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810ms/step - auc_pr: 0.9399 - auc_roc: 0.9838 - binary_acc: 0.9596 - f1_score: 0.3911 - fn: 16998.3848 - fp: 9936.7451 - loss: 0.1021 - precision: 0.9114 - recall: 0.8560 - tn: 542852.6875 - tp: 102596.1875\n",
      "Epoch 4: val_loss did not improve from 0.28995\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6509s\u001b[0m 927ms/step - auc_pr: 0.9399 - auc_roc: 0.9838 - binary_acc: 0.9596 - f1_score: 0.3911 - fn: 17000.7559 - fp: 9938.1719 - loss: 0.1021 - precision: 0.9114 - recall: 0.8560 - tn: 542930.2500 - tp: 102610.8281 - val_auc_pr: 0.4738 - val_auc_roc: 0.7429 - val_binary_acc: 0.8552 - val_f1_score: 0.3513 - val_fn: 32584.0000 - val_fp: 1788.0000 - val_loss: 0.6827 - val_precision: 0.8432 - val_recall: 0.2278 - val_tn: 193326.0000 - val_tp: 9614.0000 - learning_rate: 5.2734e-05\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 3.955078125e-05.\n",
      "Epoch 5/15\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814ms/step - auc_pr: 0.9683 - auc_roc: 0.9922 - binary_acc: 0.9730 - f1_score: 0.4084 - fn: 11170.9141 - fp: 7047.7144 - loss: 0.0698 - precision: 0.9397 - recall: 0.9061 - tn: 546072.4375 - tp: 108092.9375\n",
      "Epoch 5: val_loss did not improve from 0.28995\n",
      "\u001b[1m7003/7003\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6556s\u001b[0m 933ms/step - auc_pr: 0.9683 - auc_roc: 0.9922 - binary_acc: 0.9730 - f1_score: 0.4084 - fn: 11172.5322 - fp: 7048.7593 - loss: 0.0698 - precision: 0.9397 - recall: 0.9061 - tn: 546150.3125 - tp: 108108.3828 - val_auc_pr: 0.6359 - val_auc_roc: 0.8331 - val_binary_acc: 0.8899 - val_f1_score: 0.3884 - val_fn: 23057.0000 - val_fp: 3079.0000 - val_loss: 0.4357 - val_precision: 0.8614 - val_recall: 0.4536 - val_tn: 192037.0000 - val_tp: 19139.0000 - learning_rate: 3.9551e-05\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 2.96630859375e-05.\n",
      "Epoch 6/15\n",
      "\u001b[1m1446/7003\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:14:17\u001b[0m 802ms/step - auc_pr: 0.9835 - auc_roc: 0.9963 - binary_acc: 0.9819 - f1_score: 0.4157 - fn: 1552.4938 - fp: 965.2628 - loss: 0.0488 - precision: 0.9601 - recall: 0.9363 - tn: 113427.8047 - tp: 22966.4414"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(train_idx)\n",
    "\n",
    "hist = model.fit(df.iloc[train_idx], df.iloc[valid_idx])\n",
    "model.save('Best_EfficientNetB4_V2_sinogram_input.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
