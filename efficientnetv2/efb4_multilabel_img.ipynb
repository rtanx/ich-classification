{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-17 12:17:13.682430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734437833.702922  181447 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734437833.709220  181447 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- for working with directory ----------------------------\n",
    "ROOT_DATA_PATH='/workspace/datasets'\n",
    "DATASET_PATH=f'{ROOT_DATA_PATH}/rsna-intracranial-hemorrhage-detection'\n",
    "\n",
    "TRAIN_DATA_PATH=f'{DATASET_PATH}/stage_2_train'\n",
    "TRAIN_METADATA_PATH=f'{DATASET_PATH}/processed_metadata/train_metadata_df.pkl'\n",
    "\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreparationUtil:\n",
    "    @staticmethod\n",
    "    def correct_dcm(dcm: pydicom.FileDataset):\n",
    "        x = dcm.pixel_array\n",
    "        x = x + 1000\n",
    "        px_mode = 4096\n",
    "        x[x >= px_mode] = x[x >= px_mode] - px_mode\n",
    "        dcm.PixelData = x.tobytes()\n",
    "        dcm.RescaleIntercept = -1000\n",
    "        \n",
    "    @staticmethod\n",
    "    def window_image(dcm: pydicom.FileDataset, window_center: int, window_width: int):\n",
    "        if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n",
    "            ImagePreparationUtil.correct_dcm(dcm)\n",
    "        \n",
    "        # Pixel to Hounsfield Unit (HU)\n",
    "        # HU=(Pixel Value×RescaleSlope)+RescaleIntercept\n",
    "        img = dcm.pixel_array\n",
    "        img = img * dcm.RescaleSlope + dcm.RescaleIntercept \n",
    "        img_min = window_center - window_width // 2\n",
    "        img_max = window_center + window_width // 2\n",
    "        img = np.clip(img, img_min, img_max)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_windowed_image(dcm: pydicom.FileDataset, window: Union['brain', 'subdural', 'soft'] = 'brain') -> np.ndarray: # type: ignore\n",
    "        im = None\n",
    "        match window:\n",
    "            case 'brain':\n",
    "                brain_img = ImagePreparationUtil.window_image(dcm, 40, 80)\n",
    "                brain_img = (brain_img - 0) / 80\n",
    "                im = brain_img\n",
    "            case 'subdural':\n",
    "                subdural_img = ImagePreparationUtil.window_image(dcm, 80, 200)\n",
    "                subdural_img = (subdural_img - (-20)) / 200\n",
    "                im = subdural_img\n",
    "            case 'soft':\n",
    "                soft_img = ImagePreparationUtil.window_image(dcm, 40, 380)\n",
    "                soft_img = (soft_img - (-150)) / 380\n",
    "                im = soft_img\n",
    "            case _:\n",
    "                raise ValueError('invalid window argument')\n",
    "        \n",
    "        return im\n",
    "    \n",
    "    @staticmethod\n",
    "    def bsb_window(dcm):\n",
    "        brain_img = ImagePreparationUtil.get_windowed_image(dcm, window='brain')\n",
    "        subdural_img = ImagePreparationUtil.get_windowed_image(dcm, window='subdural')\n",
    "        soft_img = ImagePreparationUtil.get_windowed_image(dcm, window='soft')\n",
    "\n",
    "        bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n",
    "\n",
    "        return bsb_img\n",
    "    \n",
    "    @staticmethod\n",
    "    def read(path, resize: Tuple[int, int]):\n",
    "        img = None\n",
    "        try:\n",
    "            dcm = pydicom.dcmread(path)\n",
    "            img = ImagePreparationUtil.bsb_window(dcm)\n",
    "        except Exception as e:\n",
    "            print('\\nWarning:', e.__class__.__name__, f'for {path} Replacing with zeros image')\n",
    "            img = np.zeros((*tuple(resize[:2]), 3), dtype=np.float32)\n",
    "        \n",
    "        if resize is not None:\n",
    "            img = cv2.resize(img, resize[:2], interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "        return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, img_ids, labels, img_dir, img_shape, num_classes, batch_size, under_sampling=False, shuffle_on_epoch_end=True, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.img_ids = img_ids\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.under_sampling = under_sampling\n",
    "        self.shuffle_on_epoch_end = shuffle_on_epoch_end\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.img_ids) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low = index*self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.img_ids))\n",
    "        indices = self.indices[low:high]\n",
    "        X,y = self.__data_generation(indices)\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_ids))\n",
    "        \n",
    "        if self.under_sampling:\n",
    "            keep_prob = self.labels.iloc[:,0].map({0: 0.35, 1: 0.5})\n",
    "            keep = (keep_prob > np.random.rand(len(keep_prob)))\n",
    "            self.indices = self.indices[keep]\n",
    "            \n",
    "        if self.shuffle_on_epoch_end:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_shape))\n",
    "        y = np.empty((self.batch_size, self.num_classes), dtype=np.float32)\n",
    "        \n",
    "        for i, img_idx in enumerate(indices):\n",
    "            img_id = self.img_ids[img_idx]\n",
    "            img_path = f'{self.img_dir}/{img_id}.dcm'\n",
    "            img = ImagePreparationUtil.read(img_path, self.img_shape[:2])\n",
    "            X[i,] = img\n",
    "            y[i,] = self.labels.iloc[img_idx].values\n",
    "            \n",
    "        return X,y\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_99196d0ab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_2b0190b58</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_056e14224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_525e72262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b00eddf10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_21e825c20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_85141c704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b4add57dd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_02f0d7dbb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_7d29263ce</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263606 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                                          \\\n",
       "Diagnosis      any epidural intraparenchymal intraventricular subarachnoid   \n",
       "Image                                                                        \n",
       "ID_99196d0ab     1        0                0                0            0   \n",
       "ID_2b0190b58     0        0                0                0            0   \n",
       "ID_056e14224     1        1                0                0            0   \n",
       "ID_525e72262     0        0                0                0            0   \n",
       "ID_b00eddf10     0        0                0                0            0   \n",
       "...            ...      ...              ...              ...          ...   \n",
       "ID_21e825c20     0        0                0                0            0   \n",
       "ID_85141c704     1        0                1                0            0   \n",
       "ID_b4add57dd     0        0                0                0            0   \n",
       "ID_02f0d7dbb     0        0                0                0            0   \n",
       "ID_7d29263ce     1        0                0                0            0   \n",
       "\n",
       "                       \n",
       "Diagnosis    subdural  \n",
       "Image                  \n",
       "ID_99196d0ab        1  \n",
       "ID_2b0190b58        0  \n",
       "ID_056e14224        0  \n",
       "ID_525e72262        0  \n",
       "ID_b00eddf10        0  \n",
       "...               ...  \n",
       "ID_21e825c20        0  \n",
       "ID_85141c704        1  \n",
       "ID_b4add57dd        0  \n",
       "ID_02f0d7dbb        0  \n",
       "ID_7d29263ce        1  \n",
       "\n",
       "[263606 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(TRAIN_METADATA_PATH)\n",
    "test_df_neg = df[df['Label']['any'] == 0].sample(n=200)\n",
    "test_df_pos = df[df['Label']['any'] == 1].sample(n=200)\n",
    "test_df = pd.concat([test_df_pos, test_df_neg]).sample(frac=1)\n",
    "df = df.drop(test_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "0    146510\n",
       "1    117096\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "1    200\n",
       "0    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateLogger(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_lr = self.model.optimizer.learning_rate(self.model.optimizer.iterations).numpy()\n",
    "        print(f\"Epoch {epoch+1}: Learning rate is set to {current_lr:.6f}\")\n",
    "        \n",
    "class DeepModel():\n",
    "    def __init__(self, base,input_shape, batch_size, num_epochs, num_classes, learning_rate, decay_rate, decay_steps, base_name='base_model', weights='imagenet', freeze_base=False, saving_path=None, verbose=1):\n",
    "        self.base = base\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.base_name = base_name\n",
    "        self.weights = weights\n",
    "        self.freeze_base = freeze_base\n",
    "        self.saving_path = saving_path\n",
    "        self.verbose = verbose\n",
    "        self._build()\n",
    "        self._create_saving_path_if_none()\n",
    "    \n",
    "    def _build(self):\n",
    "        K.clear_session()\n",
    "        base = self.base(include_top=False, weights=self.weights, pooling='avg', input_shape=self.input_shape)\n",
    "        base.trainable = not self.freeze_base\n",
    "            \n",
    "        x = base.output\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        out = layers.Dense(self.num_classes, activation='sigmoid', name='dense_output')(x)\n",
    "        \n",
    "        self.model = keras.models.Model(inputs=base.input, outputs=out)\n",
    "        \n",
    "        lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=self.learning_rate,\n",
    "            decay_steps=self.decay_steps,\n",
    "            decay_rate=self.decay_rate,\n",
    "            staircase=True,\n",
    "        )\n",
    "        \n",
    "        self.model.compile(\n",
    "            loss=keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "            metrics=[\n",
    "                keras.metrics.TruePositives(name='tp'),\n",
    "                keras.metrics.TrueNegatives(name='tn'),\n",
    "                keras.metrics.FalsePositives(name='fp'),\n",
    "                keras.metrics.FalseNegatives(name='fn'),\n",
    "                keras.metrics.BinaryAccuracy(name='binary_acc'), \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc_roc', curve='ROC', multi_label=True, num_labels=self.num_classes),\n",
    "                keras.metrics.AUC(name='auc_pr', curve='PR', multi_label=True, num_labels=self.num_classes),\n",
    "                keras.metrics.F1Score(name='f1_score', average='weighted'),                \n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def _create_saving_path_if_none(self):\n",
    "        if self.saving_path is None:\n",
    "            print('saving_path is None. Automatically create path for save training utilities')\n",
    "            saving_path = os.path.join('saved_model', self.base.__name__)\n",
    "            os.makedirs(saving_path, exist_ok=True)\n",
    "            self.saving_path = saving_path\n",
    "            print(self.saving_path, 'created for saving_path')\n",
    "        \n",
    "    def fit(self, train_df, valid_df):\n",
    "        train_data_gen = TrainDataGenerator(\n",
    "            img_ids=train_df.index, \n",
    "            labels=train_df,\n",
    "            img_dir=TRAIN_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        valid_data_gen = TrainDataGenerator(\n",
    "            img_ids=valid_df.index, \n",
    "            labels=valid_df,\n",
    "            img_dir=TRAIN_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        curr_time = int(time.time())\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(filepath='%s/{epoch:02d}-%s.weights.h5' % (self.saving_path, curr_time), monitor='val_loss', mode='min', verbose=self.verbose, save_weights_only=True, save_best_only=True),\n",
    "            LearningRateLogger(),\n",
    "            keras.callbacks.EarlyStopping(verbose=1, restore_best_weights=True, monitor='val_loss', patience=5, mode='min'),\n",
    "            keras.callbacks.CSVLogger(filename='%s/%s.csv'%(self.saving_path, f'{curr_time}-train_log'))\n",
    "        ]\n",
    "        return self.model.fit(\n",
    "            x=train_data_gen,\n",
    "            validation_data=valid_data_gen,\n",
    "            callbacks=callbacks,\n",
    "            epochs=self.num_epochs,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "    \n",
    "    def save(self, filename, overwrite=True):\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        if ext != '.keras':\n",
    "          filename = f'{filename}.keras'\n",
    "          \n",
    "        p = os.path.join(self.saving_path, filename)\n",
    "        self.model.save(p, overwrite=overwrite)\n",
    "        print('model saved to:', p)\n",
    "        \n",
    "    def load_weights(self, path, *args, **kwargs):\n",
    "        self.model.load_weights(path, *args, **kwargs)\n",
    "        \n",
    "    def load(self, path, *args, **kwargs):\n",
    "        self.model = keras.models.load_model(path, *args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 15\n",
    "INPUT_SHAPE = (256, 256, 3)\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "msss = MultilabelStratifiedShuffleSplit(n_splits=EPOCH, test_size=0.15, random_state=SEED)\n",
    "X = df.index\n",
    "Y = df['Label'].values\n",
    "\n",
    "msss_splits = next(msss.split(X, Y))\n",
    "train_idx = msss_splits[0]\n",
    "valid_idx = msss_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = math.ceil(len(train_idx)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = 'saved_model/EfficientNetB4_V2_image_input'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "\n",
    "model = DeepModel(\n",
    "    base=keras.applications.EfficientNetB4,\n",
    "    weights='imagenet',\n",
    "    freeze_base=False,\n",
    "    input_shape=INPUT_SHAPE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_epochs=EPOCH,\n",
    "    num_classes=N_CLASSES,\n",
    "    learning_rate=0.000125, \n",
    "    decay_rate=0.8, \n",
    "    decay_steps=2*steps_per_epoch,\n",
    "    base_name='efficientnetb4',\n",
    "    saving_path=saving_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_idx)\n",
    "\n",
    "hist = model.fit(df.iloc[train_idx], df.iloc[valid_idx])\n",
    "model.save('Best_EfficientNetB4_V2_image_input.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
