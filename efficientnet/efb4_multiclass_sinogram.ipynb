{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "from datetime import date\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- for working with directory ----------------------------\n",
    "ROOT_DATA_PATH='/workspace/datasets'\n",
    "DATASET_PATH=f'{ROOT_DATA_PATH}/rsna-intracranial-hemorrhage-detection'\n",
    "\n",
    "TRAIN_DATA_PATH=f'{DATASET_PATH}/stage_2_train'\n",
    "TRAIN_SINOGRAM_DATA_PATH=f'{DATASET_PATH}/stage_2_train_sinogram'\n",
    "TRAIN_METADATA_PATH=f'{DATASET_PATH}/processed_metadata/train_metadata_df.pkl'\n",
    "\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (360, 362)\n",
    "IMG_SHAPE = (*IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeding\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sinogram(fpath):\n",
    "    im = None\n",
    "    try:\n",
    "        im = np.load(fpath).astype(np.float32)\n",
    "    except Exception as e:\n",
    "        print('\\nWarning:', e.__class__.__name__, f'for {fpath} Replacing with zeros sinogram values')\n",
    "        im = np.zeros(IMG_SHAPE, dtype=np.float32)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSinoDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, img_ids, labels, img_dir, img_shape, num_classes, batch_size, under_sampling=False, shuffle_on_epoch_end=True, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.img_ids = img_ids\n",
    "        self.labels = labels\n",
    "        self.img_dir = img_dir\n",
    "        self.img_shape = img_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.under_sampling = under_sampling\n",
    "        self.shuffle_on_epoch_end = shuffle_on_epoch_end\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.img_ids) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        low = index*self.batch_size\n",
    "        high = min(low + self.batch_size, len(self.img_ids))\n",
    "        indices = self.indices[low:high]\n",
    "        X,y = self.__data_generation(indices)\n",
    "\n",
    "        return X,y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_ids))\n",
    "        \n",
    "        if self.under_sampling:\n",
    "            keep_prob = self.labels.iloc[:,0].map({0: 0.35, 1: 0.5})\n",
    "            keep = (keep_prob > np.random.rand(len(keep_prob)))\n",
    "            self.indices = self.indices[keep]\n",
    "            \n",
    "        if self.shuffle_on_epoch_end:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        \n",
    "    def __data_generation(self, indices):\n",
    "        X = np.empty((self.batch_size, *self.img_shape))\n",
    "        y = np.empty((self.batch_size, self.num_classes), dtype=np.float32)\n",
    "        \n",
    "        for i, img_idx in enumerate(indices):\n",
    "            img_id = self.img_ids[img_idx]\n",
    "            img_path = f'{self.img_dir}/{img_id}.npy'\n",
    "            img = read_sinogram(img_path)\n",
    "            X[i,] = img\n",
    "            y[i,] = self.labels.iloc[img_idx].values\n",
    "            \n",
    "        return X,y\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID_99196d0ab</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_2b0190b58</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_056e14224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_525e72262</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b00eddf10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_21e825c20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_85141c704</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_b4add57dd</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_02f0d7dbb</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_7d29263ce</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263606 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                                          \\\n",
       "Diagnosis      any epidural intraparenchymal intraventricular subarachnoid   \n",
       "Image                                                                        \n",
       "ID_99196d0ab     1        0                0                0            0   \n",
       "ID_2b0190b58     0        0                0                0            0   \n",
       "ID_056e14224     1        1                0                0            0   \n",
       "ID_525e72262     0        0                0                0            0   \n",
       "ID_b00eddf10     0        0                0                0            0   \n",
       "...            ...      ...              ...              ...          ...   \n",
       "ID_21e825c20     0        0                0                0            0   \n",
       "ID_85141c704     1        0                1                0            0   \n",
       "ID_b4add57dd     0        0                0                0            0   \n",
       "ID_02f0d7dbb     0        0                0                0            0   \n",
       "ID_7d29263ce     1        0                0                0            0   \n",
       "\n",
       "                       \n",
       "Diagnosis    subdural  \n",
       "Image                  \n",
       "ID_99196d0ab        1  \n",
       "ID_2b0190b58        0  \n",
       "ID_056e14224        0  \n",
       "ID_525e72262        0  \n",
       "ID_b00eddf10        0  \n",
       "...               ...  \n",
       "ID_21e825c20        0  \n",
       "ID_85141c704        1  \n",
       "ID_b4add57dd        0  \n",
       "ID_02f0d7dbb        0  \n",
       "ID_7d29263ce        1  \n",
       "\n",
       "[263606 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(TRAIN_METADATA_PATH)\n",
    "test_df_neg = df[df['Label']['any'] == 0].sample(n=200)\n",
    "test_df_pos = df[df['Label']['any'] == 1].sample(n=200)\n",
    "test_df = pd.concat([test_df_pos, test_df_neg]).sample(frac=1)\n",
    "df = df.drop(test_df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "0    146510\n",
       "1    117096\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any\n",
       "1    200\n",
       "0    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Label']['any'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinoDeepModel():\n",
    "    def __init__(self, base,input_shape, batch_size, num_epochs, num_classes, learning_rate, decay_rate, decay_steps, base_name='base_model', weights='imagenet', freeze_base=False, saving_path=None, verbose=1):\n",
    "        self.base = base\n",
    "        self.input_shape = input_shape\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_classes = num_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.base_name = base_name\n",
    "        self.weights = weights\n",
    "        self.freeze_base = freeze_base\n",
    "        self.saving_path = saving_path\n",
    "        self.verbose = verbose\n",
    "        self._build()\n",
    "        self._create_saving_path_if_none()\n",
    "    \n",
    "    def _build(self):\n",
    "        K.clear_session()\n",
    "        base = self.base(include_top=False, weights=self.weights, pooling='avg', input_shape=self.input_shape)\n",
    "        base.trainable = not self.freeze_base\n",
    "            \n",
    "        x = base.output\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "        out = layers.Dense(self.num_classes, activation='sigmoid', name='dense_output')(x)\n",
    "        \n",
    "        self.model = keras.models.Model(inputs=base.input, outputs=out)\n",
    "        \n",
    "        \n",
    "        self.model.compile(\n",
    "            loss=keras.losses.BinaryCrossentropy(), \n",
    "            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),\n",
    "            metrics=[\n",
    "                keras.metrics.BinaryAccuracy(name='binary_acc'), \n",
    "                keras.metrics.Precision(name='precision'),\n",
    "                keras.metrics.Recall(name='recall'),\n",
    "                keras.metrics.AUC(name='auc_roc', curve='ROC'),\n",
    "                keras.metrics.AUC(name='auc_pr', curve='PR'),\n",
    "                keras.metrics.F1Score(name='f1_score'),\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def _create_saving_path_if_none(self):\n",
    "        if self.saving_path is None:\n",
    "            print('saving_path is None. Automatically create path for save training utilities')\n",
    "            saving_path = os.path.join('saved_model', self.base.__name__)\n",
    "            os.makedirs(saving_path, exist_ok=True)\n",
    "            self.saving_path = saving_path\n",
    "            print(self.saving_path, 'created for saving_path')\n",
    "        \n",
    "    def fit(self, train_df, valid_df):\n",
    "        train_data_gen = TrainSinoDataGenerator(\n",
    "            img_ids=train_df.index, \n",
    "            labels=train_df,\n",
    "            img_dir=TRAIN_SINOGRAM_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        valid_data_gen = TrainSinoDataGenerator(\n",
    "            img_ids=valid_df.index, \n",
    "            labels=valid_df,\n",
    "            img_dir=TRAIN_SINOGRAM_DATA_PATH,\n",
    "            img_shape=self.input_shape,\n",
    "            num_classes=self.num_classes,\n",
    "            batch_size=self.batch_size,\n",
    "            under_sampling=False,\n",
    "            workers=128,\n",
    "            use_multiprocessing=True\n",
    "        )\n",
    "        \n",
    "        curr_time = int(time.time())\n",
    "        callbacks = [\n",
    "            keras.callbacks.ModelCheckpoint(filepath='%s/{epoch:02d}-%s.weights.h5' % (self.saving_path, curr_time), monitor='val_loss', mode='min', verbose=self.verbose, save_weights_only=True, save_best_only=True),\n",
    "            keras.callbacks.LearningRateScheduler(lambda epoch: self.learning_rate * pow(self.decay_rate, math.floor(epoch / self.decay_steps)), verbose=1),\n",
    "            keras.callbacks.EarlyStopping(verbose=1, restore_best_weights=True, monitor='val_loss', patience=5, mode='min'),\n",
    "            keras.callbacks.CSVLogger(filename='%s/%s.csv'%(self.saving_path, f'{curr_time}-train_log'))\n",
    "        ]\n",
    "        return self.model.fit(\n",
    "            x=train_data_gen,\n",
    "            validation_data=valid_data_gen,\n",
    "            callbacks=callbacks,\n",
    "            epochs=self.num_epochs,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "    \n",
    "    def save(self, filename, overwrite=True):\n",
    "        _, ext = os.path.splitext(filename)\n",
    "        if ext != '.keras':\n",
    "          filename = f'{filename}.keras'\n",
    "          \n",
    "        p = os.path.join(self.saving_path, filename)\n",
    "        self.model.save(p, overwrite=overwrite)\n",
    "        print('model saved to:', p)\n",
    "        \n",
    "    def load_weights(self, path, *args, **kwargs):\n",
    "        self.model.load_weights(path, *args, **kwargs)\n",
    "        \n",
    "    def load(self, path, *args, **kwargs):\n",
    "        self.model = keras.models.load_model(path, *args, **kwargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10\n",
    "INPUT_SHAPE = IMG_SHAPE\n",
    "BATCH_SIZE = 32\n",
    "N_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734356083.351743  156611 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8225 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.10gb, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "saving_path = 'saved_model/EfficientNetB4_Sino'\n",
    "os.makedirs(saving_path, exist_ok=True)\n",
    "model = SinoDeepModel(\n",
    "    base=keras.applications.EfficientNetB4,\n",
    "    weights='imagenet',\n",
    "    freeze_base=False,\n",
    "    input_shape=INPUT_SHAPE, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    num_epochs=EPOCH,\n",
    "    num_classes=N_CLASSES,\n",
    "    learning_rate=0.000125, \n",
    "    decay_rate=0.5, \n",
    "    decay_steps=1,\n",
    "    saving_path=saving_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "msss = MultilabelStratifiedShuffleSplit(n_splits=EPOCH, test_size=0.15, random_state=SEED)\n",
    "X = df.index\n",
    "Y = df['Label'].values\n",
    "\n",
    "msss_splits = next(msss.split(X, Y))\n",
    "train_idx = msss_splits[0]\n",
    "valid_idx = msss_splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_idx)\n",
    "\n",
    "hist = model.fit(df.iloc[train_idx], df.iloc[valid_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_efficientnetb4_sino.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
